{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ead10e",
   "metadata": {},
   "source": [
    "# Overspeed detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630df238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating new tracker0\n",
      " Creating new tracker1\n",
      " Creating new tracker2\n",
      " Creating new tracker3\n",
      " Creating new tracker4\n",
      " Creating new tracker5\n",
      " Creating new tracker6\n",
      "Removing carID 4 from list of trackers. \n",
      "Removing carID 4 previous location. \n",
      "Removing carID 4 current location. \n",
      " Creating new tracker7\n",
      " Creating new tracker8\n",
      " Creating new tracker9\n",
      "Removing carID 7 from list of trackers. \n",
      "Removing carID 7 previous location. \n",
      "Removing carID 7 current location. \n",
      "Removing carID 9 from list of trackers. \n",
      "Removing carID 9 previous location. \n",
      "Removing carID 9 current location. \n",
      "Removing carID 2 from list of trackers. \n",
      "Removing carID 2 previous location. \n",
      "Removing carID 2 current location. \n",
      " Creating new tracker10\n",
      " Creating new tracker11\n",
      " Creating new tracker12\n",
      "Removing carID 1 from list of trackers. \n",
      "Removing carID 1 previous location. \n",
      "Removing carID 1 current location. \n",
      "Removing carID 11 from list of trackers. \n",
      "Removing carID 11 previous location. \n",
      "Removing carID 11 current location. \n",
      "Removing carID 10 from list of trackers. \n",
      "Removing carID 10 previous location. \n",
      "Removing carID 10 current location. \n",
      " Creating new tracker13\n",
      " Creating new tracker14\n",
      " Creating new tracker15\n",
      " Creating new tracker16\n",
      " Creating new tracker17\n",
      " Creating new tracker18\n",
      "Removing carID 13 from list of trackers. \n",
      "Removing carID 13 previous location. \n",
      "Removing carID 13 current location. \n",
      "Removing carID 14 from list of trackers. \n",
      "Removing carID 14 previous location. \n",
      "Removing carID 14 current location. \n",
      "Removing carID 16 from list of trackers. \n",
      "Removing carID 16 previous location. \n",
      "Removing carID 16 current location. \n",
      " Creating new tracker19\n",
      " Creating new tracker20\n",
      "Removing carID 19 from list of trackers. \n",
      "Removing carID 19 previous location. \n",
      "Removing carID 19 current location. \n",
      " Creating new tracker21\n",
      " Creating new tracker22\n",
      "Removing carID 21 from list of trackers. \n",
      "Removing carID 21 previous location. \n",
      "Removing carID 21 current location. \n",
      "Removing carID 22 from list of trackers. \n",
      "Removing carID 22 previous location. \n",
      "Removing carID 22 current location. \n",
      "Removing carID 12 from list of trackers. \n",
      "Removing carID 12 previous location. \n",
      "Removing carID 12 current location. \n",
      "Removing carID 20 from list of trackers. \n",
      "Removing carID 20 previous location. \n",
      "Removing carID 20 current location. \n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries final \n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Classifier File\n",
    "carCascade = cv2.CascadeClassifier(\"C:\\\\Users\\\\deepp\\\\Codebook\\\\vehicle-speed-detection\\\\vech.xml\")\n",
    "\n",
    "#Video file capture\n",
    "video = cv2.VideoCapture(\"C:\\\\Users\\\\deepp\\\\Codebook\\\\vehicle-speed-detection\\\\carsVideo.mp4\")\n",
    "\n",
    "# Constant Declaration\n",
    "WIDTH =1280\n",
    "HEIGHT = 720\n",
    "\n",
    "#estimate speed function\n",
    "def estimateSpeed(location1, location2):\n",
    "    d_pixels = math.sqrt(math.pow(location2[0] - location1[0], 2) + math.pow(location2[1] - location1[1], 2))\n",
    "    ppm = 8.8\n",
    "    d_meters = d_pixels / ppm\n",
    "    fps = 18\n",
    "    speed = d_meters * fps * 3.6\n",
    "    return speed\n",
    "\n",
    "#tracking multiple objects\n",
    "def trackMultipleObjects():\n",
    "    rectangleColor = (0, 255, 255)\n",
    "    frameCounter = 0\n",
    "    currentCarID = 0\n",
    "    fps = 0\n",
    "\n",
    "    carTracker = {}\n",
    "    carNumbers = {}\n",
    "    carLocation1 = {}\n",
    "    carLocation2 = {}\n",
    "    speed = [None] * 1000\n",
    "\n",
    "    out = cv2.VideoWriter('outTraffic.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 10, (WIDTH, HEIGHT))\n",
    "\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "        rc, image = video.read()\n",
    "        if type(image) == type(None):\n",
    "            break\n",
    "\n",
    "        image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "        resultImage = image.copy()\n",
    "\n",
    "        frameCounter = frameCounter + 1\n",
    "        carIDtoDelete = []\n",
    "\n",
    "        for carID in carTracker.keys():\n",
    "            trackingQuality = carTracker[carID].update(image)\n",
    "\n",
    "            if trackingQuality < 7:\n",
    "                carIDtoDelete.append(carID)\n",
    "\n",
    "        \n",
    "        for carID in carIDtoDelete:\n",
    "            print(\"Removing carID \" + str(carID) + ' from list of trackers. ')\n",
    "            print(\"Removing carID \" + str(carID) + ' previous location. ')\n",
    "            print(\"Removing carID \" + str(carID) + ' current location. ')\n",
    "            carTracker.pop(carID, None)\n",
    "            carLocation1.pop(carID, None)\n",
    "            carLocation2.pop(carID, None)\n",
    "\n",
    "        \n",
    "        if not (frameCounter % 10):\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cars = carCascade.detectMultiScale(gray, 1.1, 13, 18, (24, 24))\n",
    "\n",
    "            for (_x, _y, _w, _h) in cars:\n",
    "                x = int(_x)\n",
    "                y = int(_y)\n",
    "                w = int(_w)\n",
    "                h = int(_h)\n",
    "\n",
    "                x_bar = x + 0.5 * w\n",
    "                y_bar = y + 0.5 * h\n",
    "\n",
    "                matchCarID = None\n",
    "\n",
    "                for carID in carTracker.keys():\n",
    "                    trackedPosition = carTracker[carID].get_position()\n",
    "\n",
    "                    t_x = int(trackedPosition.left())\n",
    "                    t_y = int(trackedPosition.top())\n",
    "                    t_w = int(trackedPosition.width())\n",
    "                    t_h = int(trackedPosition.height())\n",
    "\n",
    "                    t_x_bar = t_x + 0.5 * t_w\n",
    "                    t_y_bar = t_y + 0.5 * t_h\n",
    "\n",
    "                    if ((t_x <= x_bar <= (t_x + t_w)) and (t_y <= y_bar <= (t_y + t_h)) and (x <= t_x_bar <= (x + w)) and (y <= t_y_bar <= (y + h))):\n",
    "                        matchCarID = carID\n",
    "\n",
    "                if matchCarID is None:\n",
    "                    print(' Creating new tracker' + str(currentCarID))\n",
    "\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    tracker.start_track(image, dlib.rectangle(x, y, x + w, y + h))\n",
    "\n",
    "                    carTracker[currentCarID] = tracker\n",
    "                    carLocation1[currentCarID] = [x, y, w, h]\n",
    "\n",
    "                    currentCarID = currentCarID + 1\n",
    "\n",
    "        for carID in carTracker.keys():\n",
    "            trackedPosition = carTracker[carID].get_position()\n",
    "\n",
    "            t_x = int(trackedPosition.left())\n",
    "            t_y = int(trackedPosition.top())\n",
    "            t_w = int(trackedPosition.width())\n",
    "            t_h = int(trackedPosition.height())\n",
    "\n",
    "            cv2.rectangle(resultImage, (t_x, t_y), (t_x + t_w, t_y + t_h), rectangleColor, 4)\n",
    "\n",
    "            carLocation2[carID] = [t_x, t_y, t_w, t_h]\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if not (end_time == start_time):\n",
    "            fps = 1.0/(end_time - start_time)\n",
    "\n",
    "        for i in carLocation1.keys():\n",
    "            if frameCounter % 1 == 0:\n",
    "                [x1, y1, w1, h1] = carLocation1[i]\n",
    "                [x2, y2, w2, h2] = carLocation2[i]\n",
    "\n",
    "                carLocation1[i] = [x2, y2, w2, h2]\n",
    "\n",
    "                if [x1, y1, w1, h1] != [x2, y2, w2, h2]:\n",
    "                    if (speed[i] == None or speed[i] == 0) and y1 >= 275 and y1 <= 285:\n",
    "                        speed[i] = estimateSpeed([x1, y1, w1, h1], [x1, y2, w2, h2])\n",
    "\n",
    "                    if speed[i] != None and y1 >= 180:\n",
    "                        cv2.putText(resultImage, str(int(speed[i])) + \"km/h\", (int(x1 + w1/2), int(y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 100) ,2)\n",
    "\n",
    "        cv2.imshow('result', resultImage)\n",
    "\n",
    "        out.write(resultImage)\n",
    "\n",
    "        if cv2.waitKey(15) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trackMultipleObjects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d557fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c14fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5deb8d2",
   "metadata": {},
   "source": [
    "# helmet detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb74f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d85d462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d8dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helmet detection final code\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "cascade_src = \"D:\\\\Study\\\\Other\\\\Helmet-Detection--Computer-Vision-\\\\bike.xml\"\n",
    "video_src = \"D:\\\\Study\\\\Other\\\\Helmet-Detection--Computer-Vision-\\\\movie2.mp4\"\n",
    "cap = cv2.VideoCapture(video_src)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "car_cascade = cv2.CascadeClassifier(cascade_src)\n",
    "\n",
    "# Set up GUI\n",
    "window = tk.Tk()  # Makes main window\n",
    "window.wm_title(\"Digital Microscope\")\n",
    "window.config(background=\"#FFFFFF\")\n",
    "\n",
    "# Graphics window\n",
    "imageFrame = tk.Frame(window, width=600, height=500)\n",
    "imageFrame.grid(row=0, column=0, padx=10, pady=2)\n",
    "\n",
    "# Capture video frames\n",
    "lmain = tk.Label(imageFrame)\n",
    "lmain.grid(row=0, column=0)\n",
    "\n",
    "\n",
    "def show_frame():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.59, 1)\n",
    "\n",
    "    for (x, y, w, h) in cars:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 215), 2)\n",
    "        cv2.putText(frame, \"Helmet\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 215), 2)\n",
    "\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    img = Image.fromarray(color)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image=imgtk)\n",
    "    lmain.after(10, show_frame)\n",
    "\n",
    "\n",
    "def close_window():\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    window.destroy()\n",
    "\n",
    "\n",
    "# Slider window (slider controls stage position)\n",
    "sliderFrame = tk.Frame(window, width=600, height=100)\n",
    "sliderFrame.grid(row=600, column=0, padx=10, pady=2)\n",
    "\n",
    "# Bind the 'q' key press event to the close_window function\n",
    "window.bind('q', lambda event: close_window())\n",
    "\n",
    "show_frame()  # Display\n",
    "window.mainloop()  # Start GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239e121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e58db0c0",
   "metadata": {},
   "source": [
    "# tripping bike detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee079db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'trafficenv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Saqlain/Desktop/traffic detection/trafficenv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#working done\n",
    "\n",
    "import cv2\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "face_detector = cv2.CascadeClassifier(\"D:\\\\Codebook\\\\Triple_riding_detection\\\\haar_IS_haar.xml\")\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"D:\\\\Codebook\\\\Triple_riding_detection\\\\frame.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# Draw bounding boxes around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "    cv2.putText(img, 'Face', (x, y), font, 2, (255, 0, 0), 5)\n",
    "\n",
    "# Display the image with bounding boxes and face count\n",
    "cv2.putText(img, 'Number of Faces: ' + str(len(faces)), (40, 40), font, 1, (255, 0, 0), 2)\n",
    "cv2.imshow('Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce7dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615b376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## triple riding for vedio \n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load pre-trained model for person detection (e.g., Haar cascades or deep learning models)\n",
    "person_cascade = cv2.CascadeClassifier(\"D:\\\\Study\\\\haarcascades\\\\haarcascade_fullbody.xml\")\n",
    "\n",
    "# Initialize video capture from a camera or video file\n",
    "video_path = \"path/to/video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for person detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform person detection\n",
    "    persons = person_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Count the number of persons detected\n",
    "    num_persons = len(persons)\n",
    "\n",
    "    # Check if triple riding is detected\n",
    "    if num_persons >= 3:\n",
    "        triple_riding_detected = True\n",
    "    else:\n",
    "        triple_riding_detected = False\n",
    "\n",
    "    # Draw bounding boxes around the detected persons\n",
    "    for (x, y, w, h) in persons:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Triple Riding Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67052bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c6af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd37014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621af93d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ddde50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fc4b57",
   "metadata": {},
   "source": [
    "# number plate detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd1f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "640b219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture image from vedio file final \n",
    "# save in seperate folder\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read input video\n",
    "video_path = \"D:\\\\Codebook\\\\No_plate_detection\\\\demo.mp4\" # Replace with the path of your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Read haarcascade for number plate detection\n",
    "cascade = cv2.CascadeClassifier(\"D:\\\\Study\\\\haarcascades\\\\haarcascade_russian_plate_number.xml\")\n",
    "\n",
    "# Create a folder to store captured number plates if it doesn't exist\n",
    "folder_path = \"D:\\\\Codebook\\\\No_plate_detection\\\\CapturedPlates\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Counter for generating unique names\n",
    "counter = 1\n",
    "\n",
    "while True:\n",
    "    # Read frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if no frames are read or end of the video is reached\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect license number plates\n",
    "    plates = cascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "    # Loop over all plates\n",
    "    for (x, y, w, h) in plates:\n",
    "        # Draw bounding rectangle around the license number plate\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        gray_plates = gray[y:y+h, x:x+w]\n",
    "        color_plates = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Save number plate detected with a unique name\n",
    "        image_name = os.path.join(folder_path, 'Numberplate_' + str(counter) + '.jpg')\n",
    "        cv2.imwrite(image_name, gray_plates)\n",
    "        counter += 1\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Number Plate Image', frame)\n",
    "\n",
    "    # Check for 'q' key press to exit the loop\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff8e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ece34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d2d2145",
   "metadata": {},
   "source": [
    "## signal light detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f60c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load pre-trained vehicle detection model (e.g., Haar cascades or deep learning models)\n",
    "car_cascade = cv2.CascadeClassifier(\"D:\\\\Codebook\\\\exam\\\\harcascade file\\\\haarcascade_car.xml\")\n",
    "\n",
    "# Load pre-trained signal detection model or implement signal detection algorithm\n",
    "signal_cascade = cv2.CascadeClassifier(\"D:\\\\Codebook\\\\Traffic_light_detection\\\\cascade.xml\")\n",
    "\n",
    "# Define color ranges for red, yellow, and green signals (adjust as per your requirements)\n",
    "red_lower = np.array([0, 0, 100], dtype=np.uint8)\n",
    "red_upper = np.array([20, 255, 255], dtype=np.uint8)\n",
    "yellow_lower = np.array([20, 0, 100], dtype=np.uint8)\n",
    "yellow_upper = np.array([40, 255, 255], dtype=np.uint8)\n",
    "green_lower = np.array([40, 0, 100], dtype=np.uint8)\n",
    "green_upper = np.array([70, 255, 255], dtype=np.uint8)\n",
    "\n",
    "# Define ROI coordinates (adjust as per your requirements)\n",
    "roi_x, roi_y, roi_width, roi_height = 100, 100, 200, 200\n",
    "\n",
    "# Initialize video capture from a camera or video file\n",
    "video_path = \"D:\\\\Codebook\\\\Traffic_light_detection\\\\demo.avi\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract the ROI from the frame\n",
    "    roi = frame[roi_y:roi_y+roi_height, roi_x:roi_x+roi_width]\n",
    "\n",
    "    # Convert ROI to the HSV color space\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Perform color thresholding to detect red, yellow, and green signals\n",
    "    mask_red = cv2.inRange(hsv_roi, red_lower, red_upper)\n",
    "    mask_yellow = cv2.inRange(hsv_roi, yellow_lower, yellow_upper)\n",
    "    mask_green = cv2.inRange(hsv_roi, green_lower, green_upper)\n",
    "\n",
    "    # Count the number of non-zero pixels in each mask\n",
    "    red_pixels = np.count_nonzero(mask_red)\n",
    "    yellow_pixels = np.count_nonzero(mask_yellow)\n",
    "    green_pixels = np.count_nonzero(mask_green)\n",
    "\n",
    "    # Determine the signal state based on the number of pixels in each mask\n",
    "    signal_state = None\n",
    "    if red_pixels > yellow_pixels and red_pixels > green_pixels:\n",
    "        signal_state = \"Red\"\n",
    "    elif yellow_pixels > red_pixels and yellow_pixels > green_pixels:\n",
    "        signal_state = \"Yellow\"\n",
    "    elif green_pixels > red_pixels and green_pixels > yellow_pixels:\n",
    "        signal_state = \"Green\"\n",
    "\n",
    "    # Draw the signal state text on the frame\n",
    "    cv2.putText(frame, f\"Signal State: {signal_state}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with the ROI and signal state\n",
    "    cv2.imshow('Signal State Analysis', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e01a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889dec08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
